use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use tokio::sync::Semaphore;
use futures::stream::{self, StreamExt};
use indicatif::{ProgressBar, ProgressStyle, MultiProgress};
use std::time::Duration;
use crate::models::PoolData;
use crate::sources::{
    PoolSource, 
    gecko::GeckoTerminal, 
    aggregators::{DexScreenerSource, MatchaSource},
    meta_agg::{self, MatchaTokenResolver, KyberSwapDirectSource, OpenOceanDirectSource, ParaSwapDirectSource},
};
use super::{PoolCache, PoolFilter};

/// Collection statistics for monitoring
#[derive(Default)]
pub struct CollectorStats {
    pub total_requests: AtomicUsize,
    pub successful: AtomicUsize,
    pub failed: AtomicUsize,
    pub pools_collected: AtomicUsize,
}

#[derive(Debug)]
pub struct CollectorResult {
    pub total: usize,
    pub successful: usize,
    pub failed: usize,
}

pub struct PoolCollector {
    sources: Vec<Arc<dyn PoolSource>>,
    cache: Arc<PoolCache>,
    filter: PoolFilter,
    semaphore: Arc<Semaphore>,
    stats: Arc<CollectorStats>,
}

impl PoolCollector {
    pub fn new(cache: Arc<PoolCache>, filter: PoolFilter) -> Self {
        // Shared token address cache for aggregators
        let token_cache = meta_agg::new_token_cache();
        
        Self {
            // All 7 active sources with shared token cache
            sources: vec![
                // Primary sources (always work)
                Arc::new(GeckoTerminal::new()),
                Arc::new(DexScreenerSource::new()),
                // Token resolver (populates cache for others)
                Arc::new(MatchaTokenResolver::new(token_cache.clone())),
                // Aggregators using shared cache
                Arc::new(KyberSwapDirectSource::new(token_cache.clone())),
                Arc::new(OpenOceanDirectSource::new(token_cache.clone())),
                Arc::new(ParaSwapDirectSource::new(token_cache.clone())),
                // Original Matcha (for comparison)
                Arc::new(MatchaSource::new()),
            ],
            cache,
            filter,
            semaphore: Arc::new(Semaphore::new(10)),
            stats: Arc::new(CollectorStats::default()),
        }
    }

    /// Progressive collection with visual feedback
    pub async fn collect_progressive(&self, symbols: &[String]) -> CollectorResult {
        let mp = MultiProgress::new();
        
        let pb_total = mp.add(ProgressBar::new(symbols.len() as u64));
        pb_total.set_style(ProgressStyle::default_bar()
            .template("{prefix:.bold.blue} [{bar:40.cyan/blue}] {pos}/{len} {msg}")
            .unwrap()
            .progress_chars("â–ˆâ–“â–’â–‘"));
        pb_total.set_prefix("ğŸ“Š Collecting");

        let total_pools = Arc::new(AtomicUsize::new(0));
        let successful = Arc::new(AtomicUsize::new(0));
        let failed = Arc::new(AtomicUsize::new(0));

        stream::iter(symbols.iter().cloned())
            .map(|symbol| {
                let pb = pb_total.clone();
                let sources = self.sources.clone();
                let cache = self.cache.clone();
                let filter = self.filter.clone();
                let semaphore = self.semaphore.clone();
                let total_pools = total_pools.clone();
                let successful = successful.clone();
                let failed = failed.clone();

                async move {
                    let _permit = semaphore.acquire().await.unwrap();
                    
                    // ğŸ”¥ ë””ë²„ê·¸: í† í° ì²˜ë¦¬ ì‹œì‘
                    tracing::debug!("\nğŸ” ì²˜ë¦¬ ì¤‘: {}", symbol);
                    
                    let mut source_results: Vec<String> = Vec::new();
                    
                    for source in sources.iter() {
                        let source_name = source.name();
                        pb.set_message(format!("{} â† {}", symbol, source_name));
                        
                        match tokio::time::timeout(
                            Duration::from_secs(10),
                            source.fetch_pools(&symbol)
                        ).await {
                            Ok(Ok(pools)) => {
                                let pool_count = pools.len();
                                
                                // ğŸ”¥ ë””ë²„ê·¸: ì†ŒìŠ¤ë³„ ê²°ê³¼
                                tracing::info!("  âœ… {}: {}ì—ì„œ {}ê°œ í’€ ìˆ˜ì‹ ", 
                                    symbol, source_name, pool_count);
                                
                                let before_filter = pools.len();
                                let filtered: Vec<_> = pools.into_iter()
                                    .filter(|p| {
                                        let valid = filter.is_valid(p);
                                        // ğŸ”¥ ë””ë²„ê·¸: í•„í„°ë§ëœ í’€ ìƒì„¸
                                        if !valid {
                                            tracing::debug!("    â­ï¸ í•„í„°ë¨: {} @ {} (ê°€ê²©=${:.4}, LP=${:.0}, Vol=${:.0})",
                                                p.symbol, p.dex, p.price_usd, p.lp_reserve_usd, p.volume_24h);
                                        }
                                        valid
                                    })
                                    .collect();
                                
                                let after_filter = filtered.len();
                                // ğŸ”¥ ë””ë²„ê·¸: í•„í„° ê²°ê³¼ ìš”ì•½
                                tracing::info!("    â†’ í•„í„°: {}/{} í†µê³¼ ({}ê°œ ì œê±°)", 
                                    after_filter, before_filter, before_filter - after_filter);
                                
                                for pool in filtered {
                                    let key = format!("{}:{}:{}", pool.source, pool.chain, pool.pool_address);
                                    cache.insert(key, pool);
                                    total_pools.fetch_add(1, Ordering::Relaxed);
                                }
                                successful.fetch_add(1, Ordering::Relaxed);
                                
                                if pool_count > 0 {
                                    source_results.push(format!("{}:{}", source_name, pool_count));
                                }
                            }
                            Ok(Err(e)) => {
                                // ğŸ”¥ ë””ë²„ê·¸: API ì—ëŸ¬
                                tracing::warn!("  âŒ {}: {} ì‹¤íŒ¨ - {}", 
                                    symbol, source_name, e);
                                failed.fetch_add(1, Ordering::Relaxed);
                            }
                            Err(_) => {
                                // ğŸ”¥ ë””ë²„ê·¸: íƒ€ì„ì•„ì›ƒ
                                tracing::warn!("  â±ï¸ {}: {} íƒ€ì„ì•„ì›ƒ (10ì´ˆ)", 
                                    symbol, source_name);
                                failed.fetch_add(1, Ordering::Relaxed);
                            }
                        }
                    }

                    pb.inc(1);
                    let sources_info = if source_results.is_empty() {
                        "ì—†ìŒ".to_string()
                    } else {
                        source_results.join(" | ")
                    };
                    pb.set_message(format!("{} [{}]", symbol, sources_info));
                }
            })
            .buffer_unordered(5)
            .collect::<Vec<_>>()
            .await;

        pb_total.finish_with_message(format!("âœ“ {}ê°œ í’€ ìˆ˜ì§‘ ì™„ë£Œ", total_pools.load(Ordering::Relaxed)));

        CollectorResult {
            total: total_pools.load(Ordering::Relaxed),
            successful: successful.load(Ordering::Relaxed),
            failed: failed.load(Ordering::Relaxed),
        }
    }

    /// Get all cached pools
    pub fn get_cached_pools(&self) -> Vec<Arc<PoolData>> {
        self.cache.get_all()
    }

    /// Get collection statistics
    pub fn get_stats(&self) -> Arc<CollectorStats> {
        self.stats.clone()
    }
}